{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**\n",
        "\n",
        "Hello, This project consists of a neural network that is being used in order to detect images of chess pieces and classify it as either a 'bishop', 'pawn', 'knight', 'king' or 'queen'\n",
        "\n",
        "In this project, I've utilised a dataset from kaggle that contains a variety of chess pieces from the website Chess.com. For this reason, the project's goal is to be able to classify a given digital chess piece (probably from chess.com) into their respective class.\n",
        "\n"
      ],
      "metadata": {
        "id": "JKSToiD-Md1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from shutil import copy2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import regularizers"
      ],
      "metadata": {
        "id": "L3XTn7AKQhoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the given code snippet in order to download the dataset \n",
        "\n",
        "The dataset contains 6 classes corresponding to each piece, and contains a total of 517 images\n"
      ],
      "metadata": {
        "id": "kJdqJa9Zpzs4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ug4BebRQYg3h"
      },
      "outputs": [],
      "source": [
        "#Run to Download the Zip File containing the images\n",
        "!wget -O ChessFile.zip https://www.dropbox.com/s/le5xf56zcmxs6uh/ihlded.zip?dl=0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code snippet below unzips the file"
      ],
      "metadata": {
        "id": "uhdy4D9YYnDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = \"/content/ChessFile.zip\"\n",
        "zip_ref2 = zipfile.ZipFile(zip_ref,'r')\n",
        "zip_ref2.extractall(\"ChessProject\")\n",
        "\n",
        "zip_ref2.close()"
      ],
      "metadata": {
        "id": "Rre18yRrYmik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are 2 functions that handle the data splitting and directory creation\n",
        "\n",
        "When splitting the data, we use a ratio such that 80% of the data goes to the training directory, whereas 20% go to the validation directory\n"
      ],
      "metadata": {
        "id": "l9VpyzWveu7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_directories(dir):\n",
        "  tr = os.path.join(dir,\"training\")\n",
        "  os.makedirs(tr,exist_ok=True)\n",
        "  va = os.path.join(dir,\"validation\")\n",
        "  b = [\"rook\",\"queen\",\"pawn\",\"knight\",\"bishop\",\"king\"]\n",
        "  for a in b:\n",
        "    path1 = os.path.join(tr,a)\n",
        "    path2 = os.path.join(va,a)\n",
        "    os.makedirs(path1,exist_ok=True)\n",
        "    os.makedirs(path2,exist_ok=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zu3wHBHqtK9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(SOURCE_DIR,TRAINING_DIR,VALIDATION_DIR):\n",
        "  k = os.listdir(SOURCE_DIR)\n",
        "  a = random.sample(k,len(k))\n",
        "  count = 0\n",
        "  #the 0.8, shows that 80% of the data goes to the trianing directory\n",
        "  limit = len(a) * 0.8\n",
        "  for image in a:\n",
        "    if(count<=limit):\n",
        "      copy2(os.path.join(SOURCE_DIR,image),TRAINING_DIR)\n",
        "      count+=1\n",
        "    else:\n",
        "      copy2(os.path.join(SOURCE_DIR,image),VALIDATION_DIR)\n"
      ],
      "metadata": {
        "id": "N4ij2zevv1Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "create_directories(\"/content\")\n",
        "split_data(\"/content/ChessProject/data/queen\",\"/content/training/queen\",\"/content/validation/queen\")\n",
        "split_data(\"/content/ChessProject/data/rook\",\"/content/training/rook\",\"/content/validation/rook\")\n",
        "split_data(\"/content/ChessProject/data/bishop\",\"/content/training/bishop\",\"/content/validation/bishop\")\n",
        "split_data(\"/content/ChessProject/data/knight\",\"/content/training/knight\",\"/content/validation/knight\")\n",
        "split_data(\"/content/ChessProject/data/pawn\",\"/content/training/pawn\",\"/content/validation/pawn\")\n",
        "split_data(\"/content/ChessProject/data/king\",\"/content/training/king\",\"/content/validation/king\")"
      ],
      "metadata": {
        "id": "ZLI6oRibwnWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this code, to see some of the images that will be used during Training(3 images of each class should've been printed)\n"
      ],
      "metadata": {
        "id": "x4cj0uKKYE0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "rookar = os.listdir(\"/content/training/rook\")\n",
        "bishopar = os.listdir(\"/content/training/bishop\")\n",
        "knightar = os.listdir(\"/content/training/knight\")\n",
        "kingar = os.listdir(\"/content/training/king\")\n",
        "queenar = os.listdir(\"/content/training/queen\")\n",
        "pawnar = os.listdir(\"/content/training/pawn\")\n",
        "directoriess = [(\"/content/training/rook\"),(\"/content/training/bishop\"),(\"/content/training/knight\"),(\"/content/training/king\"),(\"/content/training/queen\"),(\"/content/training/pawn\")]\n",
        "for directory in directoriess:\n",
        "    # Get the list of image file names using os.listdir()\n",
        "    image_files = os.listdir(directory)\n",
        "    count = 0\n",
        "    # Loop through the image files\n",
        "    for image_file in image_files:\n",
        "        if(count==3):\n",
        "          break\n",
        "        # Load the image using PIL (Python Imaging Library)\n",
        "     \n",
        "        image_path = os.path.join(directory, image_file)\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # Create a new figure and plot the image\n",
        "        plt.figure()\n",
        "        plt.imshow(image)\n",
        "        count=count+1\n",
        "        plt.axis('off')  # Remove the axes and ticks\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tdjYhZthYFJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the given dataset is quite small, about 517 images where only 400 of them pertain to training, I've augmented the images using the ImageDataGenerator in order to avoid overfitting and also virtually increase the size of the dataset"
      ],
      "metadata": {
        "id": "2AIkG31ue_s8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator( rescale = 1./255,\n",
        "\t    rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      brightness_range = (0.5,1.5),\n",
        "      fill_mode='nearest')\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\"/content/training\",target_size=(85,85),class_mode=\"categorical\",batch_size=16)\n",
        "validation_generator = train_datagen.flow_from_directory(\"/content/validation\",target_size=(85,85),class_mode=\"categorical\",batch_size=16)\n"
      ],
      "metadata": {
        "id": "LnFqTydOyM_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model at hand uses 3 convolutional layers in order to extract features of the data, followed by Pooling. Batch Normalization is done after each convolution in order to accelerate convergence. Once the preprocessing is done, the pixels are flattened and passed into the Neural Network. It is then followed by three layers of Neurons with 'relu' activation, followed by a final dense layer with a softmax activation corresponding to the output"
      ],
      "metadata": {
        "id": "n01jtgfYe-ND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import regularizers\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(85,85,3)),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "     tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "      tf.keras.layers.BatchNormalization(axis=-1),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "     tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "      tf.keras.layers.BatchNormalization(axis=-1),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1024,activation='relu'),\n",
        "    tf.keras.layers.Dense(1024,activation='relu'),\n",
        "    tf.keras.layers.Dense(512,activation = 'relu'),\n",
        "    tf.keras.layers.Dense(6,activation='softmax')\n",
        "    \n",
        "])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "gPGxfVYe0LUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model with Categorical Crossentropy, and optimizing with adam, And then fitting the model"
      ],
      "metadata": {
        "id": "nJEXtv5YkQrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_generator,epochs=100,steps_per_epoch=27,validation_data=validation_generator)\n"
      ],
      "metadata": {
        "id": "aN2T0i3W1Ahj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section allows you to upload an image of your choice. The model takes in this image and provides its best guess as to what piece it is."
      ],
      "metadata": {
        "id": "wHm7DPu5kIPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = load_img(path, target_size=(85, 85))\n",
        "  x = img_to_array(img)\n",
        "  x /= 255\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  arrr = np.where(classes[0]==classes[0].max())\n",
        "  maxind = arrr[0]\n",
        "  if maxind==0:\n",
        "    print(fn + \" is a bishop\")\n",
        "  elif maxind==1:\n",
        "    print(fn + \" is a king\")\n",
        "  elif maxind==2:\n",
        "    print(fn + \" is a knight\")\n",
        "  elif maxind==3:\n",
        "    print(fn + \" is a pawn\")\n",
        "  elif maxind==4:\n",
        "    print(fn + \"is a queen\")\n",
        "  elif maxind==5:\n",
        "    print(fn + \"is a rook\")\n",
        "  else:\n",
        "    print(\"unknown\")\n"
      ],
      "metadata": {
        "id": "ssNOv-bGZpUi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}